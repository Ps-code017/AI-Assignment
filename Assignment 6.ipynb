{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7682a757",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Create dataset\n",
    "data = {\n",
    "    'experience': [2, 4, 6, 5, 3, 7, 8, 9, 1, 10],\n",
    "    'written_score': [7, 6, 8, 9, 5, 6, 7, 9, 6, 10],\n",
    "    'interview_score': [8, 7, 9, 10, 6, 5, 6, 8, 6, 9],\n",
    "    'salary': [40, 50, 70, 65, 45, 75, 80, 85, 38, 95]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Train model\n",
    "X = df[['experience', 'written_score', 'interview_score']]\n",
    "y = df['salary']\n",
    "model = KNeighborsRegressor(n_neighbors=3)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predict for new candidates\n",
    "candidates = pd.DataFrame([[5, 8, 10], [8, 7, 6]], columns=['experience', 'written_score', 'interview_score'])\n",
    "predictions = model.predict(candidates)\n",
    "print(\"Predicted salaries:\", predictions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6df268a",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Create dataset\n",
    "data = {\n",
    "    'grad_percent': [85, 70, 90, 78, 82, 95, 88, 60, 75, 92, 73, 80, 67, 85, 91, 74, 86, 90, 76, 79, 69, 81, 83, 87, 84],\n",
    "    'experience': [2, 5, 6, 7, 3, 4, 6, 2, 1, 8, 4, 3, 5, 7, 4, 6, 2, 3, 4, 7, 2, 6, 5, 4, 3],\n",
    "    'written_score': [6, 7, 8, 6, 5, 8, 9, 4, 3, 7, 6, 5, 6, 9, 8, 7, 6, 5, 5, 6, 7, 6, 8, 9, 6],\n",
    "    'interview_score': [7, 8, 6, 9, 5, 8, 9, 3, 2, 6, 7, 6, 5, 9, 8, 7, 5, 4, 5, 8, 6, 5, 9, 8, 7],\n",
    "    'selected': [1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "X = df.drop('selected', axis=1)\n",
    "y = df['selected']\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Train model\n",
    "model = GaussianNB()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Prediction\n",
    "unseen = pd.DataFrame([[90, 5, 8, 10], [75, 8, 7, 6]], columns=['grad_percent', 'experience', 'written_score', 'interview_score'])\n",
    "pred = model.predict(unseen)\n",
    "\n",
    "print(\"Predicted selections:\", pred)\n",
    "\n",
    "# Metrics\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00034e3d",
   "metadata": {},
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "\n",
    "# Try different train sizes and parameters\n",
    "for test_size in [0.2, 0.3]:\n",
    "    for depth in [2, 3, 4]:\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n",
    "        clf = DecisionTreeClassifier(criterion='entropy', max_depth=depth)\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_pred = clf.predict(X_test)\n",
    "        acc = accuracy_score(y_test, y_pred)\n",
    "        print(f\"Test size={test_size}, Max depth={depth}, Accuracy={acc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06b68aea",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "import pandas as pd\n",
    "\n",
    "# Sample classified data\n",
    "data = {\n",
    "    'f1': [1, 2, 3, 4, 5, 6, 7, 8],\n",
    "    'f2': [2, 3, 4, 5, 6, 7, 8, 9],\n",
    "    'f3': [1, 0, 1, 0, 1, 0, 1, 0],\n",
    "    'class': [0, 0, 1, 1, 0, 1, 0, 1]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "X = df.drop('class', axis=1)\n",
    "y = df['class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "# Models\n",
    "models = {\n",
    "    \"KNN\": KNeighborsClassifier(n_neighbors=3),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(criterion='entropy')\n",
    "}\n",
    "\n",
    "# Compare\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    preds = model.predict(X_test)\n",
    "    print(f\"\\n{name}:\\n\", classification_report(y_test, preds))\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
